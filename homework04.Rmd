---
title: "SMDS_Homework4"
author: "Eros Fabrici, Arianna Tasciotti, Roberto Corti"
date: "5/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## DAAG

### Chapeter 6
#### Exercise 11
```{r DAAG - Chapter 6 exercise 11}
library(DAAG)
set.seed(50)
x1 <- runif(10) # predictor which will be missing
x2 <- rbinom(10, 1, 1-x1) # observed predictor which depends
# on missing predictor
y <- 5*x1 + x2 + rnorm(10, sd=.1) # simulated model; coef
# of x2 is positive
y.lm <- lm(y ~ factor(x2)) # model fitted to observed data
coef(y.lm)
 # effect of missing variable:
# coefficient of x2 has wrong sign
y.lm2 <- lm(y ~ x1 + factor(x2)) # correct model
coef(y.lm2)

```
What happens if `x2` is generated according to `x2 <- rbinom(10, 1, x1)`?
`x2 <- rbinom(10, 1, .5)`?

```{r DAAG - Chapt. 6 exercise 11}
x2 <- rbinom(10, 1, x1) # observed predictor which depends
# on missing predictor
y <- 5*x1 + x2 + rnorm(10,sd=.1) # simulated model; coef
# of x2 is positive
y.lm <- lm(y ~ factor(x2)) # model fitted to observed data
coef(y.lm)
 # effect of missing variable:
# coefficient of x2 has wrong sign
y.lm2 <- lm(y ~ x1 + factor(x2)) # correct model
coef(y.lm2)

```
With `x2 <- rbinom(10, 1, x1)`, in the linear model $y = \beta_0+\beta_1x_2$ the `x2` coefficient has a positive effect on the response variable (before it had a negative effect, i.e. -1.03) and the intercept has still a positive effect, but lower (from $3.27$ to $1.06$). As regards the model $y = \beta_0+\beta_1x_1+\beta_2x_2$ the is no significant difference than the former situation.

```{r DAAG - Chapt. 6 exercise 11}
x2 <- rbinom(10, 1, .5) # observed predictor which depends
# on missing predictor
y <- 5*x1 + x2 + rnorm(10,sd=.1) # simulated model; coef
# of x2 is positive
y.lm <- lm(y ~ factor(x2)) # model fitted to observed data
coef(y.lm)
 # effect of missing variable:
# coefficient of x2 has wrong sign
y.lm2 <- lm(y ~ x1 + factor(x2)) # correct model
coef(y.lm2)
```
Finally, for `x2 <- rbinom(10, 1, .5)` we have that the coefficient is independent w.r.t. `x1`. The result is the first model is still that the `x2` conefficient has positive effect, and it is possible to notice that it is circa the mean of the two previous values of `x2`, i.e. 3.058855 and -1.031883. The second model still behaves in a similar way to the previous ones.

### Exercise 8

```{r DAAG - Chapter 8 exercise 8}

minor_head_injury <- head.injury
minor_head_injury <- lapply(minor_head_injury, as.factor)
model <- glm(clinically.important.brain.injury~., family = binomial, data = minor_head_injury)
summary(model)
```
The summary functions shows us that the variable GCS.decrease is not significance as it's p-value it is almost 0.5. We can then get rid of it:

```{r DAAG - Exercise 8}
model <- glm(clinically.important.brain.injury~.-GCS.decrease, family = binomial, data = minor_head_injury)
summary(model)
```




