---
title: "Lab_04: Roberto's Exercises"
author: "Roberto Corti"
date: "08/05/2020"
output: html_document
---

# DAAG Chapter 6

## Exercise 06

**The following investigates the consequences of not using a logarithmic transformation for the nihills data analysis. The second differs from the first in having a `dist x climb` interaction term, additional to linear terms in `dist` and `climb`.**

*  **Fit the two models**:
```{r echo=TRUE,results='hide',message=FALSE}
library(DAAG)
data(nihills)
nihills.lm <- lm(time ~ dist+climb, data=nihills)
nihills2.lm <- lm(time ~ dist+climb+dist:climb, data=nihills)
anova(nihills.lm, nihills2.lm)
```

* **Using the F-test result, make a tentative choice of model, and proceed to examine diagnostic plots. Are there any problematic observations? What happens if these points are removed? Refit both of the above models, and check the diagnostics again**

In order to compare the two models, let's run the above code:
```{r echo=TRUE, message=FALSE}
nihills.lm <- lm(time ~ dist+climb, data=nihills)
nihills2.lm <- lm(time ~ dist+climb+dist:climb, data=nihills)
anova(nihills.lm, nihills2.lm)
```

The result of the $F$ test give raise to a p-value, which is the probability that the $F$ statistics is grater than the one observed assuming the null hypotesis that the coefficient relative to `dist x climb` , is quite low. Thus we can reject the null hypotesis and therefore say that `nihills2.lm`, that is, the most complex model including an interaction term, appears as significantly better than Model 1 for `nihills` data. 

For having a more precise view of the two models we proceed to examine the diagnostic plots:
```{r echo=TRUE, message=FALSE, warning=FALSE}
## model: time = b0 + b1 dist + b2 climb
par(mfrow=c(2,2))
plot(nihills.lm)
```

```{r echo=TRUE, message=FALSE,warning=FALSE}
## model: time = b0 + b1 dist + b2 climb + b3 (dist x climb)
par(mfrow=c(2,2))
plot(nihills2.lm)
```


Looking to these plots of the two fit at first istance we observe that Seven Sevens obs. looks to be a suspect point. This point has an unexpected residual and looks to have a large influence to the fit.
In fact, the `Residual vs Leverage` plot  suggest that this point has a very large leverage. We think that `Seven Sevens` observation is clearly an outlier that has a great impact on the fit.
Moreover, from the diganostic plot of ``nihills.lm`` we also suspect that the points `Annalong Horseshoe`, `Flagstaff to Carling`' seems problematic since they result to have an unexpected distribution of their residuals.
Looking to the plots of `nihill.lm2` we see that `Slieve Donard` and `Meelbeg Meelmore`  also have high residuals. 

Thus, we decide to remove all of these suspected points:

```{r}
nihills <- nihills[rownames(nihills) != "Seven Sevens",]
nihills <- nihills[rownames(nihills) != "Annalong Horseshoe",]
nihills <- nihills[rownames(nihills) != "Slieve Donard",]
nihills <- nihills[rownames(nihills) != "Meelbeg Meelmore",]
nihills <- nihills[rownames(nihills) != "Flagstaff to Carling",]
```


Without these points we do the two fits another time and we are going to see whether the $F$-test is still rejected:

```{r}
# Refit models
nihills.lm <- lm(time ~ dist + climb, data = nihills)
nihills2.lm <- lm(time ~ dist + climb + dist:climb, data = nihills)
anova(nihills.lm, nihills2.lm)
```

After removing the problematic points, the $F$-test on the new fitted models shows that there is no significant improvement in the more complex model over the simple one. 

The previous tentative choice was a mistake driven by outliers. Without them, there's no statistical justification that prefers one model respect to the other.


## Exercise 08

**Apply the `lm.ridge()` function to the litters data, using the generalized cross-validation (GCV) criterion to choose the tuning parameter. (GCV is an approximation to cross-validation.)**


* **In particular, estimate the coefficients of the model relating `brainwt` to `bodywt` and `lsize` and compare with the results obtained using `lm()`.**

* **Using both ridge and ordinary regression, estimate the mean brain weight when litter size is 10 and body weight is 7. Use the bootstrap, with case-resampling, to compute approximate 95% percentile confidence intervals using each method. Compare with the interval obtained using `predict.lm()`.**

```{r, message=FALSE}
library(MASS)
data(litters)

#GCV on ridge regression
MASS::select(lm.ridge(brainwt~., data=litters, lambda = seq(0,1,0.001)))
```

Then the optimized value of the parameter $\lambda$ is 0.118. 
We now use this value and we compare simple multiple linear regression with multiple ridge regression:
```{r}
litters_lm <- lm(brainwt~., data=litters)
litters_lm
```

```{r}
litters_lm_ridge <- lm.ridge(brainwt~., data=litters, lambda = 0.118)
litters_lm_ridge
```

For ridge regression case both `bodywt` and `lsize` coefficients are penalized in favor of the intercept. 

In order to obtain the 95% percentile confidence intervals with bootstrap sampling we decided to build the following two functions that, given the formula model, the data, the number of bootsrap repetitions and the regularization parameter $\lambda$ would give as output the 95% confidence intervale for the value of `brainwt` when `lsize = 10 ` and `bodywt = 7`.
```{r}
bootsrap_lm <- function(formula, data, repetitions){
  n <- nrow(data)
  B <- repetitions
  s_vect <- array(0, B)
  for(i in 1:B) {
    ind <- sample(1:n, n, replace = TRUE)
    lm.b<-lm(formula, data=data[ind,])
    s_vect[i] <- lm.b$coefficients[1] + lm.b$coefficient[2]*10 + lm.b$coefficient[3]*7
  }
  perc_ci <- quantile(s_vect, prob=c(0.025, 0.975))
  return(perc_ci)
}

bootsrap_lm_ridge <- function(formula, data, repetitions, lambda){
  n <- nrow(data)
  B <- repetitions
  s_vect <- array(0, B)
  for(i in 1:B) {
    ind <- sample(1:n, n, replace = TRUE)
    lm.b<-lm.ridge(formula, data=data[ind,], lambda=lambda)
    s_vect[i] <- coef(lm.b)[1] + coef(lm.b)[2]*10 + coef(lm.b)[3]*7
  }
  perc_ci <- quantile(s_vect, prob=c(0.025, 0.975))
  return(perc_ci)
}

```

```{r}
bootsrap_lm(formula=brainwt~., data=litters, repetitions = 10^4)

bootsrap_lm_ridge(formula=brainwt~., data=litters, repetitions = 10^4, lambda = 0.118)
```

```{r}
estimate <- data.frame(lsize=10, bodywt=7)
predict.lm(lm(brainwt~., data=litters), estimate, interval = "confidence")
```

# DAAG Chapter 8

## Exercise 03

**Consider again the moths data set of Section 8.4.**

* **What happens to the standard error estimates when the poisson family is used in glm() instead of the quasipoisson family?**

* **Analyze the `P` moths, in the same way as the `A` moths were analyzed. Comment on the effect of transect length.**

```{r}
data("moths")
moths$habitat <- relevel(moths$habitat, ref="Lowerside")
summary(A.glm <- glm(A ~ habitat + log(meters), family=quasipoisson, data=moths))
summary(A.glm <- glm(A ~ habitat + log(meters), family=poisson, data=moths))
```

The dispersion estimate was $2.69$. Using the quasipoisson family has increased all the standard errors by a factor of $\sqrt{2.69}$ relative to the poisson family.
Standard errors and p-values taken from a model that assumed Poisson errors
would be highly misleading because even if they are low, the model takes into in account assumptions on the data that they are not true, like that the dispersion parameter is equal to 1.


```{r}
sapply(split(moths$P, moths$habitat), sum)

moths$habitat <- relevel(moths$habitat, ref="Lowerside")

P.glm <- glm(P ~ habitat + log(meters), family=quasipoisson, data=moths)

P.glm
```


The highest numbers relative to the habitat effect are in this case for SWsoak and for Disturbed.    
In contrast to what was observed for `A` species, in this case we observe that the coefficient relative to `log(meters)` is statistically significant. Then, . As a result, the length of the transect make difference to the number of moths observed. In particular for each one meter increase in transect length the number of moths increases with transect length by a factor of approximately $ e^{0.55} \simeq 1.74 $.
